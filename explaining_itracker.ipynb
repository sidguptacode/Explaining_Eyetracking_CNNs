{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "interpreting_itracker.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mounting our drive folder, which contains the dataset"
      ],
      "metadata": {
        "id": "HKZdN4GO094J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set to false if we want to use the small dataset\n",
        "use_large_dataset = True\n",
        "\n",
        "project_folder = './drive/MyDrive/CSC413Project'\n",
        "code_folder = f'{project_folder}/code'\n",
        "\n",
        "if use_large_dataset:\n",
        "  # Load and unzip the 10GB dataset file (if applicable)\n",
        "  if not Path(\"./data10gb_proc_2\").is_dir():\n",
        "    data_folder = f'{project_folder}/data10gb.zip'\n",
        "    !unzip './drive/MyDrive/CSC413Project/data/data10gb.zip'\n",
        "  else:\n",
        "    print(\"Large dataset already loaded\")\n",
        "\n",
        "else:\n",
        "  data_folder = f'{project_folder}/data'"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4-CHqBxv5B-",
        "outputId": "6569546d-25fe-40f6-ba85-e1954b8283f9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ITrackerData Preprocessing"
      ],
      "metadata": {
        "id": "ubC07e0u1Cw6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\n",
        "import torch.utils.data as data\n",
        "import scipy.io as sio\n",
        "from PIL import Image\n",
        "import os\n",
        "import os.path\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "'''\n",
        "Data loader for the iTracker.\n",
        "Use prepareDataset.py to convert the dataset from http://gazecapture.csail.mit.edu/ to proper format.\n",
        "\n",
        "Author: Petr Kellnhofer ( pkel_lnho (at) gmai_l.com // remove underscores and spaces), 2018. \n",
        "\n",
        "Website: http://gazecapture.csail.mit.edu/\n",
        "\n",
        "Cite:\n",
        "\n",
        "Eye Tracking for Everyone\n",
        "K.Krafka*, A. Khosla*, P. Kellnhofer, H. Kannan, S. Bhandarkar, W. Matusik and A. Torralba\n",
        "IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016\n",
        "\n",
        "@inproceedings{cvpr2016_gazecapture,\n",
        "Author = {Kyle Krafka and Aditya Khosla and Petr Kellnhofer and Harini Kannan and Suchendra Bhandarkar and Wojciech Matusik and Antonio Torralba},\n",
        "Title = {Eye Tracking for Everyone},\n",
        "Year = {2016},\n",
        "Booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}\n",
        "}\n",
        "\n",
        "'''\n",
        "\n",
        "MEAN_PATH = './drive/MyDrive/CSC413Project/code/'\n",
        "def loadMetadata(filename, silent = False):\n",
        "    try:\n",
        "        # http://stackoverflow.com/questions/6273634/access-array-contents-from-a-mat-file-loaded-using-scipy-io-loadmat-python\n",
        "        if not silent:\n",
        "            print('\\tReading metadata from %s...' % filename)\n",
        "        metadata = sio.loadmat(filename, squeeze_me=True, struct_as_record=False)\n",
        "    except:\n",
        "        print('\\tFailed to read the meta file \"%s\"!' % filename)\n",
        "        return None\n",
        "    return metadata\n",
        "\n",
        "class SubtractMean(object):\n",
        "    \"\"\"Normalize an tensor image with mean.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, meanImg):\n",
        "        self.meanImg = transforms.ToTensor()(meanImg / 255)\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
        "        Returns:\n",
        "            Tensor: Normalized image.\n",
        "        \"\"\"       \n",
        "        return tensor.sub(self.meanImg)\n",
        "\n",
        "\n",
        "class ITrackerData(data.Dataset):\n",
        "    def __init__(self, dataPath, split = 'train', imSize=(224,224), gridSize=(25, 25)):\n",
        "\n",
        "        self.dataPath = dataPath\n",
        "        self.imSize = imSize\n",
        "        self.gridSize = gridSize\n",
        "\n",
        "        print('Loading iTracker dataset...')\n",
        "        metaFile = os.path.join(dataPath, 'metadata.mat')\n",
        "        #metaFile = 'metadata.mat'\n",
        "        if metaFile is None or not os.path.isfile(metaFile):\n",
        "            raise RuntimeError('There is no such file %s! Provide a valid dataset path.' % metaFile)\n",
        "        self.metadata = loadMetadata(metaFile)\n",
        "        if self.metadata is None:\n",
        "            raise RuntimeError('Could not read metadata file %s! Provide a valid dataset path.' % metaFile)\n",
        "\n",
        "        self.faceMean = loadMetadata(os.path.join(MEAN_PATH, 'mean_face_224.mat'))['image_mean']\n",
        "        self.eyeLeftMean = loadMetadata(os.path.join(MEAN_PATH, 'mean_left_224.mat'))['image_mean']\n",
        "        self.eyeRightMean = loadMetadata(os.path.join(MEAN_PATH, 'mean_right_224.mat'))['image_mean']\n",
        "        \n",
        "        self.transformFace = transforms.Compose([\n",
        "            transforms.Resize(self.imSize),\n",
        "            transforms.ToTensor(),\n",
        "            SubtractMean(meanImg=self.faceMean),\n",
        "        ])\n",
        "        self.transformEyeL = transforms.Compose([\n",
        "            transforms.Resize(self.imSize),\n",
        "            transforms.ToTensor(),\n",
        "            SubtractMean(meanImg=self.eyeLeftMean),\n",
        "        ])\n",
        "        self.transformEyeR = transforms.Compose([\n",
        "            transforms.Resize(self.imSize),\n",
        "            transforms.ToTensor(),\n",
        "            SubtractMean(meanImg=self.eyeRightMean),\n",
        "        ])\n",
        "\n",
        "\n",
        "        if split == 'test':\n",
        "            mask = self.metadata['labelTest']\n",
        "        elif split == 'val':\n",
        "            mask = self.metadata['labelVal']\n",
        "        else:\n",
        "            mask = self.metadata['labelTrain']\n",
        "\n",
        "        self.indices = np.argwhere(mask)[:,0]\n",
        "        # TODO: Commented out, since we are only testing in this colab\n",
        "        # print('Loaded iTracker dataset split \"%s\" with %d records...' % (split, len(self.indices)))\n",
        "\n",
        "    def loadImage(self, path):\n",
        "        try:\n",
        "            im = Image.open(path).convert('RGB')\n",
        "        except OSError:\n",
        "            raise RuntimeError('Could not read image: ' + path)\n",
        "            #im = Image.new(\"RGB\", self.imSize, \"white\")\n",
        "\n",
        "        return im\n",
        "\n",
        "\n",
        "    def makeGrid(self, params):\n",
        "        gridLen = self.gridSize[0] * self.gridSize[1]\n",
        "        grid = np.zeros([gridLen,], np.float32)\n",
        "        \n",
        "        indsY = np.array([i // self.gridSize[0] for i in range(gridLen)])\n",
        "        indsX = np.array([i % self.gridSize[0] for i in range(gridLen)])\n",
        "        condX = np.logical_and(indsX >= params[0], indsX < params[0] + params[2]) \n",
        "        condY = np.logical_and(indsY >= params[1], indsY < params[1] + params[3]) \n",
        "        cond = np.logical_and(condX, condY)\n",
        "\n",
        "        grid[cond] = 1\n",
        "        return grid\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        index = self.indices[index]\n",
        "\n",
        "        imFacePath = os.path.join(self.dataPath, '%05d/appleFace/%05d.jpg' % (self.metadata['labelRecNum'][index], self.metadata['frameIndex'][index]))\n",
        "        imEyeLPath = os.path.join(self.dataPath, '%05d/appleLeftEye/%05d.jpg' % (self.metadata['labelRecNum'][index], self.metadata['frameIndex'][index]))\n",
        "        imEyeRPath = os.path.join(self.dataPath, '%05d/appleRightEye/%05d.jpg' % (self.metadata['labelRecNum'][index], self.metadata['frameIndex'][index]))\n",
        "\n",
        "        imFace = self.loadImage(imFacePath)\n",
        "        imEyeL = self.loadImage(imEyeLPath)\n",
        "        imEyeR = self.loadImage(imEyeRPath)\n",
        "\n",
        "        imFace = self.transformFace(imFace)\n",
        "        imEyeL = self.transformEyeL(imEyeL)\n",
        "        imEyeR = self.transformEyeR(imEyeR)\n",
        "\n",
        "        gaze = np.array([self.metadata['labelDotXCam'][index], self.metadata['labelDotYCam'][index]], np.float32)\n",
        "\n",
        "        faceGrid = self.makeGrid(self.metadata['labelFaceGrid'][index,:])\n",
        "\n",
        "        # to tensor\n",
        "        row = torch.LongTensor([int(index)])\n",
        "        faceGrid = torch.FloatTensor(faceGrid)\n",
        "        gaze = torch.FloatTensor(gaze)\n",
        "\n",
        "        return row, imFace, imEyeL, imEyeR, faceGrid, gaze\n",
        "    \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "Lwm6Dc_oqa3t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ITrackerModel Code"
      ],
      "metadata": {
        "id": "0AM4srcl1GY1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\n",
        "import argparse\n",
        "import os\n",
        "import shutil\n",
        "import time, math\n",
        "from collections import OrderedDict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "from torch.autograd.variable import Variable\n",
        "\n",
        "'''\n",
        "Pytorch model for the iTracker.\n",
        "\n",
        "Author: Petr Kellnhofer ( pkel_lnho (at) gmai_l.com // remove underscores and spaces), 2018. \n",
        "\n",
        "Website: http://gazecapture.csail.mit.edu/\n",
        "\n",
        "Cite:\n",
        "\n",
        "Eye Tracking for Everyone\n",
        "K.Krafka*, A. Khosla*, P. Kellnhofer, H. Kannan, S. Bhandarkar, W. Matusik and A. Torralba\n",
        "IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016\n",
        "\n",
        "@inproceedings{cvpr2016_gazecapture,\n",
        "Author = {Kyle Krafka and Aditya Khosla and Petr Kellnhofer and Harini Kannan and Suchendra Bhandarkar and Wojciech Matusik and Antonio Torralba},\n",
        "Title = {Eye Tracking for Everyone},\n",
        "Year = {2016},\n",
        "Booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}\n",
        "}\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "class ItrackerImageModel(nn.Module):\n",
        "    # Used for both eyes (with shared weights) and the face (with unqiue weights)\n",
        "    def __init__(self):\n",
        "        super(ItrackerImageModel, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.CrossMapLRN2d(size=5, alpha=0.0001, beta=0.75, k=1.0),\n",
        "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2, groups=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.CrossMapLRN2d(size=5, alpha=0.0001, beta=0.75, k=1.0),\n",
        "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 64, kernel_size=1, stride=1, padding=0),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return x\n",
        "\n",
        "class FaceImageModel(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(FaceImageModel, self).__init__()\n",
        "        self.conv = ItrackerImageModel()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(12*12*64, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "class FaceGridModel(nn.Module):\n",
        "    # Model for the face grid pathway\n",
        "    def __init__(self, gridSize = 25):\n",
        "        super(FaceGridModel, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(gridSize * gridSize, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class ITrackerModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ITrackerModel, self).__init__()\n",
        "        self.eyeModel = ItrackerImageModel()\n",
        "        self.faceModel = FaceImageModel()\n",
        "        self.gridModel = FaceGridModel()\n",
        "        # Joining both eyes\n",
        "        self.eyesFC = nn.Sequential(\n",
        "            nn.Linear(2*12*12*64, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            )\n",
        "        # Joining everything\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(128+64+128, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(128, 2),\n",
        "            )\n",
        "\n",
        "    def forward(self, faces, eyesLeft, eyesRight, faceGrids):\n",
        "        # Eye nets\n",
        "        xEyeL = self.eyeModel(eyesLeft)\n",
        "        xEyeR = self.eyeModel(eyesRight)\n",
        "        # Cat and FC\n",
        "        xEyes = torch.cat((xEyeL, xEyeR), 1)\n",
        "        xEyes = self.eyesFC(xEyes)\n",
        "\n",
        "        # Face net\n",
        "        xFace = self.faceModel(faces)\n",
        "        xGrid = self.gridModel(faceGrids)\n",
        "\n",
        "        # Cat all\n",
        "        x = torch.cat((xEyes, xFace, xGrid), 1)\n",
        "        x = self.fc(x)\n",
        "        \n",
        "        return x\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "5zNoF3K8wffS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models that represent different branches in the iTracker model"
      ],
      "metadata": {
        "id": "YK9Mw_J801qL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\n",
        "class LeftEyeBranch(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeftEyeBranch, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.CrossMapLRN2d(size=5, alpha=0.0001, beta=0.75, k=1.0),\n",
        "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2, groups=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.CrossMapLRN2d(size=5, alpha=0.0001, beta=0.75, k=1.0),\n",
        "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 64, kernel_size=1, stride=1, padding=0),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(12*12*64, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(128, 2),\n",
        "        )\n",
        "\n",
        "    def forward(self, faces, eyesLeft, eyesRight, faceGrids):\n",
        "        x = self.features(eyesLeft)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class RightEyeBranch(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RightEyeBranch, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.CrossMapLRN2d(size=5, alpha=0.0001, beta=0.75, k=1.0),\n",
        "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2, groups=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.CrossMapLRN2d(size=5, alpha=0.0001, beta=0.75, k=1.0),\n",
        "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 64, kernel_size=1, stride=1, padding=0),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(12*12*64, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(128, 2),\n",
        "        )\n",
        "\n",
        "    def forward(self, faces, eyesLeft, eyesRight, faceGrids):\n",
        "        x = self.features(eyesRight)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class JointEyeBranch(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(JointEyeBranch, self).__init__()\n",
        "        self.eyeModel = ItrackerImageModel()\n",
        "\n",
        "        # Joining both eyes\n",
        "        self.eyesFC = nn.Sequential(\n",
        "            nn.Linear(2*12*12*64, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(128, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, faces, eyesLeft, eyesRight, faceGrids):\n",
        "        # Eye nets (using shared weights)\n",
        "        xEyeL = self.eyeModel(eyesLeft)\n",
        "        xEyeR = self.eyeModel(eyesRight)\n",
        "        # Cat and FC\n",
        "        xEyes = torch.cat((xEyeL, xEyeR), 1)\n",
        "        xEyes = self.eyesFC(xEyes)\n",
        "        return xEyes\n",
        "\n",
        "\n",
        "class FaceBranch(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FaceBranch, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.CrossMapLRN2d(size=5, alpha=0.0001, beta=0.75, k=1.0),\n",
        "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2, groups=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.CrossMapLRN2d(size=5, alpha=0.0001, beta=0.75, k=1.0),\n",
        "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 64, kernel_size=1, stride=1, padding=0),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(12*12*64, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(64, 2),\n",
        "        )\n",
        "\n",
        "    def forward(self, faces, eyesLeft, eyesRight, faceGrids):\n",
        "        x = self.features(faces)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "5H2dgwP0xMJ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Specifying which model to run using argparser\n"
      ],
      "metadata": {
        "id": "FslwMH7v1QSe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\n",
        "import argparse\n",
        "\n",
        "def str2bool(v):\n",
        "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
        "        return True\n",
        "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
        "        return False\n",
        "    else:\n",
        "        raise argparse.ArgumentTypeError('Boolean value expected.')\n",
        "\n",
        "parser = argparse.ArgumentParser(description='iTracker-pytorch-Trainer.')\n",
        "parser.add_argument('--data_path', help=\"Path to processed dataset. It should contain metadata.mat. Use prepareDataset.py.\")\n",
        "parser.add_argument('--code_path', help=\"Path to project code.\")\n",
        "parser.add_argument('--sink', type=str2bool, nargs='?', const=True, default=False, help=\"Just sink and terminate (i.e, run a small test example)\")\n",
        "parser.add_argument('--reset', type=str2bool, nargs='?', const=True, default=False, help=\"Start from scratch (do not load).\")\n",
        "parser.add_argument('--model', help=\"Which model to use\")\n",
        "parser.add_argument('--prepopulate', type=str2bool, nargs='?', const=True, default=False, help=\"Prepopulate weights from full model into branch (branch models only).\")\n",
        "parser.add_argument('--train_last_fc_only', type=str2bool, nargs='?', const=True, default=False, help=\"If we want to only train the last FC layer.\")\n",
        "parser.add_argument('--model_name', help=\"Name of the model (used when saving checkpoints).\")\n",
        "\n",
        "\n",
        "data_path = f'./data10gb_proc_2' if use_large_dataset else f\"{data_folder}/data_small/\"\n",
        "\n",
        "\n",
        "############## Option to re-train the full model\n",
        "# args = parser.parse_args(args=['--data_path', data_path, '--code_path', f'{code_folder}', '--sink', 'false', '--reset', 'true', '--model', 'full', '--model_name', 'full_trained'])\n",
        "\n",
        "############## Options to create a branch model, prepopulate it with weights from the pretrained full model, and train it's final FC layer only\n",
        "# args = parser.parse_args(args=['--data_path', data_path, '--code_path', f'{code_folder}', '--sink', 'false', '--reset', 'true', '--model', 'left_eye', '--prepopulate', 'true', '--train_last_fc_only', 'true', '--model_name', 'left_eye_transfer_lastFCtrained'])\n",
        "# args = parser.parse_args(args=['--data_path', data_path, '--code_path', f'{code_folder}', '--sink', 'false', '--reset', 'true', '--model', 'right_eye', '--prepopulate', 'true', '--train_last_fc_only', 'true', '--model_name', 'right_eye_transfer_lastFCtrained'])\n",
        "# args = parser.parse_args(args=['--data_path', data_path, '--code_path', f'{code_folder}', '--sink', 'false', '--reset', 'true', '--model', 'joint_eye', '--prepopulate', 'true', '--train_last_fc_only', 'true', '--model_name', 'joint_eye_transfer_lastFCtrained'])\n",
        "# args = parser.parse_args(args=['--data_path', data_path, '--code_path', f'{code_folder}', '--sink', 'false', '--reset', 'true', '--model', 'face', '--prepopulate', 'true', '--train_last_fc_only', 'true', '--model_name', 'face_transfer_lastFCtrained'])\n",
        "\n",
        "\n",
        "############## Options that are the same as above (create branch, prepopulate it with weights), except we re-train all layers of the branch (for fine-tuning)\n",
        "# args = parser.parse_args(args=['--data_path', data_path, '--code_path', f'{code_folder}', '--sink', 'false', '--reset', 'true', '--model', 'left_eye', '--prepopulate', 'true', '--train_last_fc_only', 'false', '--model_name', 'left_eye_transfer_fulltrained'])\n",
        "# args = parser.parse_args(args=['--data_path', data_path, '--code_path', f'{code_folder}', '--sink', 'false', '--reset', 'true', '--model', 'right_eye', '--prepopulate', 'true', '--train_last_fc_only', 'false', '--model_name', 'right_eye_transfer_fulltrained'])\n",
        "# args = parser.parse_args(args=['--data_path', data_path, '--code_path', f'{code_folder}', '--sink', 'false', '--reset', 'true', '--model', 'joint_eye', '--prepopulate', 'true', '--train_last_fc_only', 'false', '--model_name', 'joint_eye_transfer_fulltrained'])\n",
        "# args = parser.parse_args(args=['--data_path', data_path, '--code_path', f'{code_folder}', '--sink', 'false', '--reset', 'true', '--model', 'face', '--prepopulate', 'true', '--train_last_fc_only', 'false', '--model_name', 'face_transfer_fulltrained'])\n",
        "\n",
        "\n",
        "############## Options to create a branch model, and retrain it fully (no transfer learning)\n",
        "# args = parser.parse_args(args=['--data_path', data_path, '--code_path', f'{code_folder}', '--sink', 'false', '--reset', 'true', '--model', 'left_eye',  '--model_name', 'left_eye_fulltrained'])\n",
        "# args = parser.parse_args(args=['--data_path', data_path, '--code_path', f'{code_folder}', '--sink', 'false', '--reset', 'true', '--model', 'right_eye', '--model_name', 'right_eye_fulltrained'])\n",
        "# args = parser.parse_args(args=['--data_path', data_path, '--code_path', f'{code_folder}', '--sink', 'false', '--reset', 'true', '--model', 'joint_eye', '--model_name', 'joint_eye_fulltrained'])\n",
        "# args = parser.parse_args(args=['--data_path', data_path, '--code_path', f'{code_folder}', '--sink', 'false', '--reset', 'true', '--model', 'face', '--model_name', 'face_fulltrained'])\n",
        "\n",
        "\n",
        "############## Options to load a pre-trained branch model, and test it\n",
        "# args = parser.parse_args(args=['--data_path', data_path, '--code_path', f'{code_folder}', '--sink', 'true', '--reset', 'false', '--model', 'left_eye',  '--model_name', 'left_eye_transfer_fulltrained'])\n",
        "# args = parser.parse_args(args=['--data_path', data_path, '--code_path', f'{code_folder}', '--sink', 'true', '--reset', 'false', '--model', 'right_eye',  '--model_name', 'right_eye_transfer_fulltrained'])\n",
        "# args = parser.parse_args(args=['--data_path', data_path, '--code_path', f'{code_folder}', '--sink', 'true', '--reset', 'false', '--model', 'face',  '--model_name', 'face_transfer_fulltrained'])\n",
        "# args = parser.parse_args(args=['--data_path', data_path, '--code_path', f'{code_folder}', '--sink', 'true', '--reset', 'false', '--model', 'full', '--model_name', 'full_pretrained'])\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "wWMTQRtGySTm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and validation loops"
      ],
      "metadata": {
        "id": "4GFBYYV11S-O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\n",
        "\n",
        "import math, shutil, os, time, argparse\n",
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "'''\n",
        "Train/test code for iTracker.\n",
        "\n",
        "Author: Petr Kellnhofer ( pkel_lnho (at) gmai_l.com // remove underscores and spaces), 2018. \n",
        "\n",
        "Website: http://gazecapture.csail.mit.edu/\n",
        "\n",
        "Cite:\n",
        "\n",
        "Eye Tracking for Everyone\n",
        "K.Krafka*, A. Khosla*, P. Kellnhofer, H. Kannan, S. Bhandarkar, W. Matusik and A. Torralba\n",
        "IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016\n",
        "\n",
        "@inproceedings{cvpr2016_gazecapture,\n",
        "Author = {Kyle Krafka and Aditya Khosla and Petr Kellnhofer and Harini Kannan and Suchendra Bhandarkar and Wojciech Matusik and Antonio Torralba},\n",
        "Title = {Eye Tracking for Everyone},\n",
        "Year = {2016},\n",
        "Booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}\n",
        "}\n",
        "\n",
        "'''\n",
        "\n",
        "# Change there flags to control what happens.\n",
        "\n",
        "doTrainLastFC = args.train_last_fc_only # Train only the last FC layer (branch models only).\n",
        "doPrepopulate = args.prepopulate # Prepopulate weights from full model into branch (branch models only).\n",
        "doLoad = not args.reset # Load checkpoint at the beginning\n",
        "doTest = args.sink # Only run test, no training\n",
        "\n",
        "workers = 16\n",
        "epochs = 1 # TODO: Play around with this value\n",
        "batch_size = torch.cuda.device_count()*100 # Change if out of cuda memory\n",
        "\n",
        "base_lr = 0.0001\n",
        "momentum = 0.9\n",
        "weight_decay = 1e-4\n",
        "print_freq = 10\n",
        "prec1 = 0\n",
        "best_prec1 = 1e20\n",
        "lr = base_lr\n",
        "\n",
        "count_test = 0\n",
        "count = 0\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    global args, best_prec1, weight_decay, momentum\n",
        "    \n",
        "\n",
        "\n",
        "def train(train_loader, model, criterion,optimizer, epoch):\n",
        "    global count\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "\n",
        "    print(len(train_loader))\n",
        "    for i, (row, imFace, imEyeL, imEyeR, faceGrid, gaze) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
        "        \n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "        imFace = imFace.cuda()\n",
        "        imEyeL = imEyeL.cuda()\n",
        "        imEyeR = imEyeR.cuda()\n",
        "        faceGrid = faceGrid.cuda()\n",
        "        gaze = gaze.cuda()\n",
        "        \n",
        "        imFace = torch.autograd.Variable(imFace, requires_grad = True)\n",
        "        imEyeL = torch.autograd.Variable(imEyeL, requires_grad = True)\n",
        "        imEyeR = torch.autograd.Variable(imEyeR, requires_grad = True)\n",
        "        faceGrid = torch.autograd.Variable(faceGrid, requires_grad = True)\n",
        "        gaze = torch.autograd.Variable(gaze, requires_grad = False)\n",
        "\n",
        "        # compute output\n",
        "        output = model(imFace, imEyeL, imEyeR, faceGrid)\n",
        "\n",
        "        loss = criterion(output, gaze)\n",
        "        \n",
        "        losses.update(loss.data.item(), imFace.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        count=count+1\n",
        "\n",
        "        print('Epoch (train): [{0}][{1}/{2}]\\t'\n",
        "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
        "                   epoch, i, len(train_loader), batch_time=batch_time,\n",
        "                   data_time=data_time, loss=losses))\n",
        "\n",
        "def validate(val_loader, model, criterion, epoch):\n",
        "    global count_test\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    lossesLin = AverageMeter()\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "    end = time.time()\n",
        "\n",
        "    print(\"Number of test samples:\", len(val_loader))\n",
        "    print(\"Batch size:\", batch_size)\n",
        "\n",
        "    oIndex = 0\n",
        "    for i, (row, imFace, imEyeL, imEyeR, faceGrid, gaze) in enumerate(val_loader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "        imFace = imFace.cuda()\n",
        "        imEyeL = imEyeL.cuda()\n",
        "        imEyeR = imEyeR.cuda()\n",
        "        faceGrid = faceGrid.cuda()\n",
        "        gaze = gaze.cuda()\n",
        "        \n",
        "        imFace = torch.autograd.Variable(imFace, requires_grad = False)\n",
        "        imEyeL = torch.autograd.Variable(imEyeL, requires_grad = False)\n",
        "        imEyeR = torch.autograd.Variable(imEyeR, requires_grad = False)\n",
        "        faceGrid = torch.autograd.Variable(faceGrid, requires_grad = False)\n",
        "        gaze = torch.autograd.Variable(gaze, requires_grad = False)\n",
        "\n",
        "        # compute output\n",
        "        with torch.no_grad():\n",
        "            output = model(imFace, imEyeL, imEyeR, faceGrid)\n",
        "\n",
        "        loss = criterion(output, gaze)\n",
        "        \n",
        "        lossLin = output - gaze\n",
        "        lossLin = torch.mul(lossLin,lossLin)\n",
        "        lossLin = torch.sum(lossLin,1)\n",
        "        lossLin = torch.mean(torch.sqrt(lossLin))\n",
        "\n",
        "        losses.update(loss.data.item(), imFace.size(0))\n",
        "        lossesLin.update(lossLin.item(), imFace.size(0))\n",
        "     \n",
        "        # compute gradient and do SGD step\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        print('Epoch (val): [{0}][{1}/{2}]\\t'\n",
        "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                  'Error L2 {lossLin.val:.4f} ({lossLin.avg:.4f})\\t'.format(\n",
        "                    epoch, i, len(val_loader), batch_time=batch_time,\n",
        "                   loss=losses,lossLin=lossesLin))\n",
        "\n",
        "    return lossesLin.avg\n",
        "\n",
        "CHECKPOINTS_PATH = f'{args.code_path}'\n",
        "\n",
        "def load_checkpoint(filename='checkpoint.pth.tar'):\n",
        "    filename = os.path.join(CHECKPOINTS_PATH, filename)\n",
        "    print(filename)\n",
        "    if not os.path.isfile(filename):\n",
        "        print(f\"no such filename {filename}\")\n",
        "        return None\n",
        "    state = torch.load(filename)\n",
        "    return state\n",
        "\n",
        "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
        "    if not os.path.isdir(CHECKPOINTS_PATH):\n",
        "        os.makedirs(CHECKPOINTS_PATH, 0o777)\n",
        "    bestFilename = os.path.join(CHECKPOINTS_PATH, 'best_' + filename)\n",
        "    filename = os.path.join(CHECKPOINTS_PATH, filename)\n",
        "    torch.save(state, filename)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filename, bestFilename)\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
        "    lr = base_lr * (0.1 ** (epoch // 30))\n",
        "    for param_group in optimizer.state_dict()['param_groups']:\n",
        "        param_group['lr'] = lr\n",
        "\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "Q8tagJyOwqz4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading our specified model"
      ],
      "metadata": {
        "id": "_u1v1GzU1Vpc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\n",
        "if args.model == 'left_eye':\n",
        "  print(\"Creating left eye model.\")\n",
        "  model_branch = LeftEyeBranch()\n",
        "  model_branch = torch.nn.DataParallel(model_branch).cuda()\n",
        "  model = model_branch\n",
        "\n",
        "elif args.model == 'right_eye':\n",
        "  print(\"Creating right eye model.\")\n",
        "  model_branch = RightEyeBranch()\n",
        "  model_branch = torch.nn.DataParallel(model_branch).cuda()\n",
        "  model = model_branch\n",
        "\n",
        "elif args.model == 'joint_eye':\n",
        "  print(\"Creating joint eye model.\")\n",
        "  model_branch = JointEyeBranch()\n",
        "  model_branch = torch.nn.DataParallel(model_branch).cuda()\n",
        "  model = model_branch\n",
        "\n",
        "elif args.model == 'face':\n",
        "  print(\"Creating face model.\")\n",
        "  model_branch = FaceBranch()\n",
        "  model_branch = torch.nn.DataParallel(model_branch).cuda()\n",
        "  model = model_branch\n",
        "\n",
        "elif args.model == 'full':\n",
        "  pass\n",
        "else:\n",
        "    raise Exception(\"Model not recognized\")"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "JtdH4lawwQCC",
        "outputId": "45b416a6-599b-421b-f7ca-803e6f19d342"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preloading the full iTracker weights into our specific individual branches\n"
      ],
      "metadata": {
        "id": "VlNhkm7N1Y14"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\n",
        "if doPrepopulate or args.model == 'full':\n",
        "  print(\"Loading full iTracker model.\")\n",
        "  model_full = ITrackerModel()\n",
        "  model_full = torch.nn.DataParallel(model_full).cuda()    \n",
        "  model = model_full\n",
        "\n",
        "\n",
        "if doPrepopulate or (doLoad and args.model == 'full'):\n",
        "  saved = load_checkpoint(f\"checkpoint_full.pth.tar\")\n",
        "  if saved:\n",
        "    print('Loading pretrained full iTracker model')\n",
        "    print('Loading checkpoint for epoch %05d with loss %.5f (which is the mean squared error not the actual linear error)...' % (saved['epoch'], saved['best_prec1']))\n",
        "    state = saved['state_dict']\n",
        "    try:\n",
        "      model_full.module.load_state_dict(state)\n",
        "    except:\n",
        "      model_full.load_state_dict(state)\n",
        "    epoch = saved['epoch']\n",
        "    best_prec1 = saved['best_prec1']\n",
        "  else:\n",
        "    raise Exception('Tried to read iTracker checkpoint, but failed!')\n",
        "\n",
        "if doPrepopulate:\n",
        "  if args.model == 'left_eye' or args.model == 'right_eye':\n",
        "    print(f\"Setting {args.model} model with full pretrained weights\")\n",
        "    for name, branch_param in model_branch.named_parameters():\n",
        "      # Don't want to overwrite the last FC layers.\n",
        "      if 'fc' in name:\n",
        "        continue\n",
        "\n",
        "      # Removes 'module' from name\n",
        "      name = \".\".join(name.split('.')[1:])\n",
        "\n",
        "      # Can only overwrite on non-backpropogating nodes\n",
        "      branch_param.requires_grad = False\n",
        "      full_param_name = f\"module.eyeModel.{name}\"\n",
        "\n",
        "      # Begin overwriting the branch weights with the trained full ones\n",
        "      full_param = dict(model_full.state_dict())[full_param_name]\n",
        "      param_dim = len(np.shape(full_param))\n",
        "      if param_dim == 1:\n",
        "        branch_param[:] = full_param[:]\n",
        "      elif param_dim == 4:\n",
        "        branch_param[:, :, :, :] = full_param[:, :, :, :]\n",
        "      else:\n",
        "        assert False, \"Unexpected param dim\"\n",
        "\n",
        "      if not doTrainLastFC:\n",
        "        # In this case, we will want to re-train this preloaded layer\n",
        "        branch_param.requires_grad = True\n",
        "        \n",
        "    \n",
        "    # Verify that overwriting succeeded\n",
        "    assert dict(model_branch.state_dict())['module.features.4.weight'][0,0,0,0] == dict(model_full.state_dict())['module.eyeModel.features.4.weight'][0,0,0,0]\n",
        "    model = model_branch\n",
        "\n",
        "  elif args.model == 'joint_eye':\n",
        "    print(f\"Setting {args.model} model with full pretrained weights\")\n",
        "    for name, branch_param in model_branch.named_parameters():\n",
        "      # Don't want to overwrite the last FC layers.\n",
        "      if 'eyesFC.2' in name:\n",
        "        continue\n",
        "\n",
        "      # Can only overwrite on non-backpropogating nodes\n",
        "      branch_param.requires_grad = False\n",
        "      full_param_name = name\n",
        "\n",
        "      # Begin overwriting the branch weights with the trained full ones\n",
        "      full_param = dict(model_full.state_dict())[full_param_name]\n",
        "      param_dim = len(np.shape(full_param))\n",
        "      if param_dim == 1:\n",
        "        branch_param[:] = full_param[:]\n",
        "      elif param_dim == 4:\n",
        "        branch_param[:, :, :, :] = full_param[:, :, :, :]\n",
        "      elif param_dim == 2:\n",
        "        branch_param[:, :] = full_param[:, :]\n",
        "      else:\n",
        "        assert False, \"Unexpected param dim\"\n",
        "\n",
        "      if not doTrainLastFC:\n",
        "        # In this case, we will want to re-train this preloaded layer\n",
        "        branch_param.requires_grad = True\n",
        "\n",
        "    # Verify that overwriting succeeded\n",
        "    assert dict(model_branch.state_dict())['module.eyeModel.features.8.weight'][0,0,0,0] == dict(model_full.state_dict())['module.eyeModel.features.8.weight'][0,0,0,0]\n",
        "    model = model_branch\n",
        "\n",
        "  elif args.model == 'face':\n",
        "    print(f\"Setting {args.model} model with full pretrained weights\")\n",
        "    for name, branch_param in model_branch.named_parameters():\n",
        "      # Don't want to overwrite the last FC layers.\n",
        "      if 'fc.4' in name:\n",
        "        continue\n",
        "\n",
        "      # Removes 'module' from name\n",
        "      name = \".\".join(name.split('.')[1:])\n",
        "\n",
        "      # Can only overwrite on non-backpropogating nodes\n",
        "      branch_param.requires_grad = False\n",
        "      full_param_name = f\"module.faceModel.conv.{name}\" if \"features\" in name else f\"module.faceModel.{name}\"\n",
        "\n",
        "      # Begin overwriting the branch weights with the trained full ones\n",
        "      full_param = dict(model_full.state_dict())[full_param_name]\n",
        "      param_dim = len(np.shape(full_param))\n",
        "      if param_dim == 1:\n",
        "        branch_param[:] = full_param[:]\n",
        "      elif param_dim == 4:\n",
        "        branch_param[:, :, :, :] = full_param[:, :, :, :]\n",
        "      elif param_dim == 2:\n",
        "        branch_param[:, :] = full_param[:, :]\n",
        "      else:\n",
        "        assert False, \"Unexpected param dim\"\n",
        "\n",
        "      if not doTrainLastFC:\n",
        "        # In this case, we will want to re-train this preloaded layer\n",
        "        branch_param.requires_grad = True\n",
        "\n",
        "    # Verify that overwriting succeeded\n",
        "    assert dict(model_branch.state_dict())['module.features.8.weight'][0,0,0,0] == dict(model_full.state_dict())['module.faceModel.conv.features.8.weight'][0,0,0,0]\n",
        "    model = model_branch"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zDWrT_NSwQnB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load **our** pretrained branch models"
      ],
      "metadata": {
        "id": "KnJM3tYJ1bdy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\n",
        "if doLoad:\n",
        "  if args.model != 'full':\n",
        "    saved = load_checkpoint(f\"best_checkpoint_{args.model_name}.pth.tar\")\n",
        "    if saved:\n",
        "      print(f'Loading our pretrained {args.model_name} model')\n",
        "      print('Loading checkpoint for epoch %05d with loss %.5f (which is the mean squared error not the actual linear error)...' % (saved['epoch'], saved['best_prec1']))\n",
        "      state = saved['state_dict']\n",
        "      try:\n",
        "        model_branch.module.load_state_dict(state)\n",
        "      except:\n",
        "        model_branch.load_state_dict(state)\n",
        "      epoch = saved['epoch']\n",
        "      best_prec1 = saved['best_prec1']\n",
        "    else:\n",
        "      raise Exception('Tried to read iTracker checkpoint, but failed!')\n",
        "    model = model_branch\n"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "duXgqzwGwUl-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Specify train / val sets"
      ],
      "metadata": {
        "id": "QldyN8K_1d-y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\n",
        "imSize=(224,224)\n",
        "cudnn.benchmark = True   \n",
        "epoch = 0\n",
        "if doTest: # In our sample dataset, we want the train files to be tested.\n",
        "  print(\"Loading test dataset\")\n",
        "  dataTrain = ITrackerData(dataPath = args.data_path, split='train', imSize = imSize)\n",
        "  dataVal = ITrackerData(dataPath = args.data_path, split='test', imSize = imSize)\n",
        "  if use_large_dataset == False:\n",
        "    dataVal = dataTrain\n",
        "else:\n",
        "  print(\"Loading train dataset\")\n",
        "  dataTrain = ITrackerData(dataPath = args.data_path, split='train', imSize = imSize)\n",
        "  dataVal = ITrackerData(dataPath = args.data_path, split='test', imSize = imSize) \n"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-z7UKJOiw0ii"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Running the train and test loops"
      ],
      "metadata": {
        "id": "6kP6yKzM1hdk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataTrain,\n",
        "    batch_size=batch_size, shuffle=False,\n",
        "    num_workers=workers, pin_memory=True)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    dataVal,\n",
        "    batch_size=batch_size, shuffle=False,\n",
        "    num_workers=workers, pin_memory=True)\n",
        "\n",
        "\n",
        "criterion = nn.MSELoss().cuda()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr,\n",
        "                            momentum=momentum,\n",
        "                            weight_decay=weight_decay)\n",
        "\n",
        "# Runs the training / test loops\n",
        "if doTest:\n",
        "  print(\"In test!\")\n",
        "  validate(val_loader, model, criterion, epoch)\n",
        "else:\n",
        "  print(\"In train!\")\n",
        "  for epoch in range(0, epoch):\n",
        "    adjust_learning_rate(optimizer, epoch)\n",
        "      \n",
        "  print(epoch)\n",
        "  for epoch in range(epoch, epochs):\n",
        "    adjust_learning_rate(optimizer, epoch)\n",
        "\n",
        "    # train for one epoch\n",
        "    train(train_loader, model, criterion, optimizer, epoch)\n",
        "\n",
        "    # remember best prec@1 and save checkpoint\n",
        "    # is_best = prec1 < best_prec1\n",
        "    # best_prec1 = min(prec1, best_prec1)\n",
        "    save_checkpoint({\n",
        "        'epoch': epoch + 1,\n",
        "        'state_dict': model.state_dict(),\n",
        "        'best_prec1': prec1,\n",
        "    }, True, filename=f'checkpoint_{args.model_name}.pth.tar')\n",
        "\n",
        "    # evaluate on validation set\n",
        "    prec1 = validate(val_loader, model, criterion, epoch)\n"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gJp3ZTgvw9fD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DeepDream"
      ],
      "metadata": {
        "id": "cm4UlmhVUe9S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "LEFT = [25., 0.]\n",
        "RIGHT = [-25., 0.]\n",
        "UP = [0., 25.]\n",
        "DOWN = [0., -25.]\n",
        "\n",
        "\n",
        "def normalize(image):\n",
        "  im_min = np.min(image)\n",
        "  im_max = np.max(image)\n",
        "  return (image - im_min) / (im_max - im_min)\n",
        "\n",
        "\n",
        "def get_best_indices(data_loader, K=[0], I=100):\n",
        "  best_left, best_right, best_up, best_down = {}, {}, {}, {}\n",
        "  k_index = 0\n",
        "\n",
        "  for k, (row, imFace, imEyeL, imEyeR, faceGrid, gaze) in enumerate(data_loader):\n",
        "    if k < K[k_index]:\n",
        "      continue\n",
        "    if k > K[k_index]:\n",
        "      k_index += 1\n",
        "      if k_index >= len(K):\n",
        "        break\n",
        "      continue\n",
        "    print(k)\n",
        "    curr_best_left, curr_best_right, curr_best_up, curr_best_down = None, None, None, None\n",
        "    best_left_error, best_right_error, best_up_error, best_down_error = -1., -1., -1., -1.\n",
        "    for i in range(I):\n",
        "      left_error = torch.sum((gaze[i] - torch.tensor(LEFT)) ** 2)\n",
        "      if best_left_error < 0. or left_error < best_left_error:\n",
        "        curr_best_left = i\n",
        "        best_left_error = left_error\n",
        "      \n",
        "      right_error = torch.sum((gaze[i] - torch.tensor(RIGHT)) ** 2)\n",
        "      if best_right_error < 0. or right_error < best_right_error:\n",
        "        curr_best_right = i\n",
        "        best_right_error = right_error\n",
        "      \n",
        "      up_error = torch.sum((gaze[i] - torch.tensor(UP)) ** 2)\n",
        "      if best_up_error < 0. or up_error < best_up_error:\n",
        "        curr_best_up = i\n",
        "        best_up_error = up_error\n",
        "      \n",
        "      down_error = torch.sum((gaze[i] - torch.tensor(DOWN)) ** 2)\n",
        "      if best_down_error < 0. or down_error <best_down_error:\n",
        "        curr_best_down = i\n",
        "        best_down_error = down_error\n",
        "    \n",
        "    best_left[k] = curr_best_left\n",
        "    best_right[k] = curr_best_right\n",
        "    best_up[k] = curr_best_up\n",
        "    best_down[k] = curr_best_down\n",
        "  \n",
        "  return best_left, best_right, best_up, best_down\n",
        "\n",
        "\n",
        "def deep_dream(model, data_loader, target, K, indices, image_type, label, diffs_list=None):\n",
        "  results_folder = \"./drive/MyDrive/CSC413Project/results/\"\n",
        "  target = torch.tensor([target]).cuda()\n",
        "  k_index = 0\n",
        "\n",
        "  for k, (row, imFace, imEyeL, imEyeR, faceGrid, gaze) in enumerate(data_loader):\n",
        "    if k < K[k_index]:\n",
        "      continue\n",
        "    if k > K[k_index]:\n",
        "      k_index += 1\n",
        "      if k_index >= len(K):\n",
        "        break\n",
        "      continue\n",
        "    i = indices[k]\n",
        "    print(\"Start\", f\"k={k}\", f\"i={i}\")\n",
        "\n",
        "    # Get example\n",
        "    test_imFace, test_imEyeL, test_imEyeR, test_faceGrid = imFace[i], imEyeL[i], imEyeR[i], faceGrid[i]\n",
        "    start_imFace = test_imFace.numpy().copy().transpose(1,2,0)\n",
        "    start_imEyeL = test_imEyeL.numpy().copy().transpose(1,2,0)\n",
        "    start_imEyeR = test_imEyeR.numpy().copy().transpose(1,2,0)\n",
        "    \n",
        "    # Create variables\n",
        "    test_imFace = torch.autograd.Variable(test_imFace, requires_grad=True)\n",
        "    test_imEyeL = torch.autograd.Variable(test_imEyeL, requires_grad=True)\n",
        "    test_imEyeR = torch.autograd.Variable(test_imEyeR, requires_grad=True)\n",
        "    test_faceGrid = torch.autograd.Variable(test_faceGrid, requires_grad=True)\n",
        "    opt = torch.optim.SGD([test_imFace, test_imEyeL, test_imEyeR, test_faceGrid], lr=1e-3)\n",
        "\n",
        "    # Train\n",
        "    print(\"Train\", f\"k={k}\", f\"i={i}\")\n",
        "    model.eval()\n",
        "    n_epoch = 1000\n",
        "    for n in range(n_epoch):\n",
        "      opt.zero_grad()\n",
        "      output = model(test_imFace.unsqueeze(0), test_imEyeL.unsqueeze(0), test_imEyeR.unsqueeze(0), test_faceGrid.unsqueeze(0))\n",
        "      loss = torch.sum((output - target) ** 2)\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "\n",
        "    diff_sum = -1\n",
        "    if args.model == 'left_eye':\n",
        "      diff_sum = np.sum(normalize((test_imEyeL.detach().numpy().transpose(1,2,0) - start_imEyeL) ** 2))\n",
        "    elif args.model == 'right_eye':\n",
        "      diff_sum = np.sum(normalize((test_imEyeR.detach().numpy().transpose(1,2,0) - start_imEyeR) ** 2 ))\n",
        "    elif args.model == 'face':\n",
        "      diff_sum = np.sum(normalize((test_imFace.detach().numpy().transpose(1,2,0) - start_imFace) ** 2))\n",
        "    elif args.model == 'full':\n",
        "      diff_sum_left = np.sum(normalize((test_imEyeL.detach().numpy().transpose(1,2,0) - start_imEyeL) ** 2))\n",
        "      diff_sum_right = np.sum(normalize((test_imEyeR.detach().numpy().transpose(1,2,0) - start_imEyeR) ** 2 ))\n",
        "      diff_sum_face = np.sum(normalize((test_imFace.detach().numpy().transpose(1,2,0) - start_imFace) ** 2))\n",
        "      diffs_list['left'].append(diff_sum_left)\n",
        "      diffs_list['right'].append(diff_sum_right)\n",
        "      diffs_list['face'].append(diff_sum_face)\n",
        "\n",
        "\n",
        "    # Plot results\n",
        "    print(\"Plot\", f\"k={k}\", f\"i={i}\")\n",
        "    eps = 1e-5\n",
        "    if image_type == 'face' or image_type == 'full':\n",
        "      plt.imshow(normalize(start_imFace))\n",
        "      plt.axis('off')\n",
        "      plt.savefig(results_folder+f\"results_deepdream_face_{label}_orig_{k},{i}.png\")\n",
        "      plt.imshow(normalize(test_imFace.detach().numpy().transpose(1,2,0)))\n",
        "      plt.axis('off')\n",
        "      plt.savefig(results_folder+f\"results_deepdream_face_{label}_learned_{k},{i}.png\")\n",
        "      plt.imshow(normalize(np.log((test_imFace.detach().numpy().transpose(1,2,0) - start_imFace) ** 2 + eps)))\n",
        "      plt.axis('off')\n",
        "      plt.savefig(results_folder+f\"results_deepdream_face_{label}_logdiff_{k},{i}.png\")\n",
        "      plt.imshow(normalize((test_imFace.detach().numpy().transpose(1,2,0) - start_imFace) ** 2))\n",
        "      plt.axis('off')\n",
        "      plt.savefig(results_folder+f\"results_deepdream_face_{label}_diff_{k},{i}.png\")\n",
        "    if image_type == 'lefteye' or image_type == 'full':\n",
        "      plt.imshow(normalize(start_imEyeL))\n",
        "      plt.axis('off')\n",
        "      plt.savefig(results_folder+f\"results_deepdream_lefteye_{label}_orig_{k},{i}.png\")\n",
        "      plt.imshow(normalize(test_imEyeL.detach().numpy().transpose(1,2,0)))\n",
        "      plt.axis('off')\n",
        "      plt.savefig(results_folder+f\"results_deepdream_lefteye_{label}_learned_{k},{i}.png\")\n",
        "      plt.imshow(normalize(np.log((test_imEyeL.detach().numpy().transpose(1,2,0) - start_imEyeL) ** 2 + eps)))\n",
        "      plt.axis('off')\n",
        "      plt.savefig(results_folder+f\"results_deepdream_lefteye_{label}_logdiff_{k},{i}.png\")\n",
        "      plt.imshow(normalize((test_imEyeL.detach().numpy().transpose(1,2,0) - start_imEyeL) ** 2))\n",
        "      plt.axis('off')\n",
        "      plt.savefig(results_folder+f\"results_deepdream_lefteye_{label}_diff_{k},{i}.png\")\n",
        "    if image_type == 'righteye' or image_type == 'full':\n",
        "      plt.imshow(normalize(start_imEyeR))\n",
        "      plt.axis('off')\n",
        "      plt.savefig(results_folder+f\"results_deepdream_righteye_{label}_orig_{k},{i}.png\")\n",
        "      plt.imshow(normalize(test_imEyeR.detach().numpy().transpose(1,2,0)))\n",
        "      plt.axis('off')\n",
        "      plt.savefig(results_folder+f\"results_deepdream_righteye_{label}_learned_{k},{i}.png\")\n",
        "      plt.imshow(normalize(np.log((test_imEyeR.detach().numpy().transpose(1,2,0) - start_imEyeR) ** 2 + eps)))\n",
        "      plt.axis('off')\n",
        "      plt.savefig(results_folder+f\"results_deepdream_righteye_{label}_logdiff_{k},{i}.png\")\n",
        "      plt.imshow(normalize((test_imEyeR.detach().numpy().transpose(1,2,0) - start_imEyeR) ** 2 ))\n",
        "      plt.axis('off')\n",
        "      plt.savefig(results_folder+f\"results_deepdream_righteye_{label}_diff_{k},{i}.png\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "v73TN09PMfZ6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "K = [k * 15 for k in range(20)]\n",
        "\n",
        "# We used 'get_max_indices' to find these indices\n",
        "# Looking left\n",
        "left_indices = {0: 48, 15: 13, 30: 0, 45: 66, 60: 55, 75: 75, 90: 79, 105: 15, 120: 0, 135: 49, 150: 7, 165: 16, 180: 30, 195: 37, 210: 17, 225: 28, 240: 17, 255: 6, 270: 52, 285: 78}\n",
        "# Looking right\n",
        "right_indices = {0: 41, 15: 80, 30: 99, 45: 73, 60: 30, 75: 56, 90: 89, 105: 83, 120: 5, 135: 13, 150: 28, 165: 34, 180: 42, 195: 87, 210: 0, 225: 18, 240: 84, 255: 89, 270: 47, 285: 47}\n",
        "# Looking up\n",
        "up_indices = {0: 48, 15: 84, 30: 99, 45: 45, 60: 55, 75: 13, 90: 70, 105: 83, 120: 14, 135: 10, 150: 92, 165: 22, 180: 26, 195: 25, 210: 1, 225: 72, 240: 99, 255: 60, 270: 74, 285: 92}\n",
        "# Looking down\n",
        "down_indices = {0: 8, 15: 55, 30: 12, 45: 81, 60: 80, 75: 19, 90: 93, 105: 31, 120: 19, 135: 80, 150: 42, 165: 66, 180: 81, 195: 79, 210: 31, 225: 88, 240: 87, 255: 89, 270: 17, 285: 14}\n",
        "\n",
        "# Hand-picked indices\n",
        "indices = {0: 8, 15: 80, 75: 13}"
      ],
      "outputs": [],
      "metadata": {
        "id": "yKp-Ikya6OyH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "img_type = 'noplot'\n",
        "diffs_list = {'left': [], 'right': [], 'face': []}\n",
        "\n",
        "print(\"left2right\")\n",
        "deep_dream(model, train_loader, RIGHT, K, left_indices, img_type, \"left2right\", diffs_list)\n",
        "\n",
        "print(\"diffs list:\")\n",
        "print(diffs_list)\n",
        "\n",
        "\n",
        "diffs_list = {'left': [], 'right': [], 'face': []}\n",
        "print(\"right2left\")\n",
        "deep_dream(model, train_loader, LEFT, K, right_indices, img_type, \"right2left\", diffs_list)\n",
        "\n",
        "print(\"diffs list:\")\n",
        "print(diffs_list)\n",
        "\n",
        "diffs_list = {'left': [], 'right': [], 'face': []}\n",
        "print(\"up2down\")\n",
        "deep_dream(model, train_loader, DOWN, K, up_indices, img_type, \"up2down\", diffs_list)\n",
        "\n",
        "print(\"diffs list:\")\n",
        "print(diffs_list)\n",
        "\n",
        "diffs_list = {'left': [], 'right': [], 'face': []}\n",
        "print(\"down2up\")\n",
        "deep_dream(model, train_loader, UP, K, down_indices, img_type, \"down2up\", diffs_list)\n",
        "\n",
        "print(\"diffs list:\")\n",
        "print(diffs_list)"
      ],
      "outputs": [],
      "metadata": {
        "id": "4Y8Y_6tFqhUJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SmoothGrad"
      ],
      "metadata": {
        "id": "-fCZpLgArfj5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SmoothGrad classes"
      ],
      "metadata": {
        "id": "Uq2y9Ur6rpZq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class VanillaGrad(object):\n",
        "\n",
        "    def __init__(self, pretrained_model, cuda=False):\n",
        "        self.pretrained_model = pretrained_model\n",
        "        self.cuda = cuda\n",
        "        #self.pretrained_model.eval()\n",
        "\n",
        "    def __call__(self, x, index=None):\n",
        "        output = self.pretrained_model(x)\n",
        "\n",
        "        if index is None:\n",
        "            index = np.argmax(output.data.cpu().numpy())\n",
        "\n",
        "        one_hot = np.zeros((1, output.size()[-1]), dtype=np.float32)\n",
        "        one_hot[0][index] = 1\n",
        "        if self.cuda:\n",
        "            one_hot = Variable(torch.from_numpy(one_hot).cuda(), requires_grad=True)\n",
        "        else:\n",
        "            one_hot = Variable(torch.from_numpy(one_hot), requires_grad=True)\n",
        "        one_hot = torch.sum(one_hot * output)\n",
        "\n",
        "        one_hot.backward()\n",
        "\n",
        "        grad = x.grad.data.cpu().numpy()\n",
        "        grad = grad[0, :, :, :]\n",
        "\n",
        "        return grad\n",
        "\n",
        "# SmoothGrad class - modified to work with iTracker\n",
        "class SmoothGrad(VanillaGrad):\n",
        "\n",
        "    def __init__(self, pretrained_model, cuda=False, stdev_spread=0.15,\n",
        "                 n_samples=25, magnitude=True):\n",
        "        super(SmoothGrad, self).__init__(pretrained_model, cuda)\n",
        "        \"\"\"\n",
        "        self.pretrained_model = pretrained_model\n",
        "        self.features = pretrained_model.features\n",
        "        self.cuda = cuda\n",
        "        self.pretrained_model.eval()\n",
        "        \"\"\"\n",
        "        self.stdev_spread = stdev_spread\n",
        "        self.n_samples = n_samples\n",
        "        self.magnitutde = magnitude\n",
        "\n",
        "    def __call__(self, x, index=None):\n",
        "        imFace, imEyeL, imEyeR, faceGrid = x\n",
        "        imFace = imFace.data.cpu().numpy()\n",
        "        imEyeL = imEyeL.data.cpu().numpy()\n",
        "        imEyeR = imEyeR.data.cpu().numpy()\n",
        "\n",
        "        # Each branch will be treated separately\n",
        "        stdevFace = self.stdev_spread * (np.max(imFace) - np.min(imFace))\n",
        "        total_gradients_face = np.zeros_like(imFace)\n",
        "        stdevEyeL = self.stdev_spread * (np.max(imEyeL) - np.min(imEyeL))\n",
        "        total_gradients_eyeL= np.zeros_like(imEyeL)\n",
        "        stdevEyeR = self.stdev_spread * (np.max(imEyeR) - np.min(imEyeR))\n",
        "        total_gradients_eyeR = np.zeros_like(imEyeR)\n",
        "        \n",
        "        for i in range(self.n_samples):\n",
        "            noiseFace = np.random.normal(0, stdevFace, imFace.shape).astype(np.float32)\n",
        "            noiseEyeL = np.random.normal(0, stdevEyeL, imEyeL.shape).astype(np.float32)\n",
        "            noiseEyeR = np.random.normal(0, stdevEyeR, imEyeR.shape).astype(np.float32)\n",
        "\n",
        "            imFace_plus_noise = imFace + noiseFace\n",
        "            imEyeL_plus_noise = imEyeL + noiseEyeL\n",
        "            imEyeR_plus_noise = imEyeR + noiseEyeR\n",
        "\n",
        "            if self.cuda:\n",
        "                imFace_plus_noise = Variable(torch.from_numpy(imFace_plus_noise).cuda(), requires_grad=True)\n",
        "                imEyeL_plus_noise = Variable(torch.from_numpy(imEyeL_plus_noise).cuda(), requires_grad=True)\n",
        "                imEyeR_plus_noise = Variable(torch.from_numpy(imEyeR_plus_noise).cuda(), requires_grad=True)\n",
        "            else:\n",
        "                imFace_plus_noise = Variable(torch.from_numpy(imFace_plus_noise), requires_grad=True)\n",
        "                imEyeL_plus_noise = Variable(torch.from_numpy(imEyeL_plus_noise), requires_grad=True)\n",
        "                imEyeR_plus_noise = Variable(torch.from_numpy(imEyeR_plus_noise), requires_grad=True)\n",
        "\n",
        "            output = self.pretrained_model(imFace_plus_noise, imEyeL_plus_noise, imEyeR_plus_noise, faceGrid)\n",
        "\n",
        "            if index is None:\n",
        "                index = np.argmax(output.data.cpu().numpy())\n",
        "\n",
        "            one_hot = np.zeros((1, output.size()[-1]), dtype=np.float32)\n",
        "            one_hot[0][index] = 1\n",
        "            if self.cuda:\n",
        "                one_hot = Variable(torch.from_numpy(one_hot).cuda(), requires_grad=True)\n",
        "            else:\n",
        "                one_hot = Variable(torch.from_numpy(one_hot), requires_grad=True)\n",
        "            one_hot = torch.sum(one_hot * output)\n",
        "\n",
        "            if imFace_plus_noise.grad is not None:\n",
        "                imFace_plus_noise.grad.data.zero_()\n",
        "            if imEyeL_plus_noise.grad is not None:\n",
        "                imEyeL_plus_noise.grad.data.zero_()\n",
        "            if imEyeR_plus_noise.grad is not None:\n",
        "                imEyeR_plus_noise.grad.data.zero_()\n",
        "            one_hot.backward()\n",
        "\n",
        "            # Each model/branch computes different gradients\n",
        "            if args.model == 'left_eye':\n",
        "                gradEyeL  = imEyeL_plus_noise.grad.data.cpu().numpy()\n",
        "                if self.magnitutde:\n",
        "                    total_gradients_eyeL += (gradEyeL * gradEyeL)\n",
        "                else:\n",
        "                    total_gradients_eyeL += gradEyeL\n",
        "                total_gradients_eyeR = np.zeros(total_gradients_eyeL.shape)\n",
        "                total_gradients_face = np.zeros(total_gradients_eyeL.shape)\n",
        "\n",
        "            elif args.model == 'right_eye':\n",
        "                gradEyeR  = imEyeR_plus_noise.grad.data.cpu().numpy()\n",
        "                if self.magnitutde:\n",
        "                    total_gradients_eyeR += (gradEyeR * gradEyeR)\n",
        "                else:\n",
        "                    total_gradients_eyeR += gradEyeR\n",
        "\n",
        "            elif args.model == 'joint_eye':\n",
        "                gradEyeL  = imEyeL_plus_noise.grad.data.cpu().numpy()\n",
        "                gradEyeR  = imEyeR_plus_noise.grad.data.cpu().numpy()\n",
        "                if self.magnitutde:\n",
        "                    total_gradients_eyeL += (gradEyeL * gradEyeL)\n",
        "                    total_gradients_eyeR += (gradEyeR * gradEyeR)\n",
        "                else:\n",
        "                    total_gradients_eyeL += gradEyeL\n",
        "                    total_gradients_eyeR += gradEyeR\n",
        "\n",
        "            elif args.model == 'face':\n",
        "                gradFace  = imFace_plus_noise.grad.data.cpu().numpy()\n",
        "                if self.magnitutde:\n",
        "                    total_gradients_face += (gradFace * gradFace)\n",
        "                else:\n",
        "                    total_gradients_face += gradFace\n",
        "                \n",
        "            else: # full\n",
        "                gradFace  = imFace_plus_noise.grad.data.cpu().numpy()\n",
        "                gradEyeL  = imEyeL_plus_noise.grad.data.cpu().numpy()\n",
        "                gradEyeR  = imEyeR_plus_noise.grad.data.cpu().numpy()\n",
        "                if self.magnitutde:\n",
        "                    total_gradients_eyeL += (gradEyeL * gradEyeL)\n",
        "                    total_gradients_eyeR += (gradEyeR * gradEyeR)\n",
        "                    total_gradients_face += (gradFace * gradFace)\n",
        "                else:\n",
        "                    total_gradients_face += gradFace\n",
        "                    total_gradients_eyeL += gradEyeL\n",
        "                    total_gradients_eyeR += gradEyeR\n",
        "\n",
        "            avg_gradients_eyeL = total_gradients_eyeL[0, :, :, :] / self.n_samples\n",
        "            avg_gradients_face = total_gradients_face[0, :, :, :] / self.n_samples\n",
        "            avg_gradients_eyeR = total_gradients_eyeR[0, :, :, :] / self.n_samples\n",
        "\n",
        "        return avg_gradients_face, avg_gradients_eyeL, avg_gradients_eyeR\n",
        "\n",
        "def preprocess_image(img, cuda=False):\n",
        "    means=[0.485, 0.456, 0.406]\n",
        "    stds=[0.229, 0.224, 0.225]\n",
        "\n",
        "    preprocessed_img = img.copy()[: , :, ::-1]\n",
        "    for i in range(3):\n",
        "        preprocessed_img[:, :, i] = preprocessed_img[:, :, i] - means[i]\n",
        "        preprocessed_img[:, :, i] = preprocessed_img[:, :, i] / stds[i]\n",
        "    preprocessed_img = \\\n",
        "        np.ascontiguousarray(np.transpose(preprocessed_img, (2, 0, 1)))\n",
        "    preprocessed_img = torch.from_numpy(preprocessed_img)\n",
        "    preprocessed_img.unsqueeze_(0)\n",
        "    if cuda:\n",
        "        preprocessed_img = Variable(preprocessed_img.cuda(), requires_grad=True)\n",
        "    else:\n",
        "        preprocessed_img = Variable(preprocessed_img, requires_grad=True)\n",
        "\n",
        "    return preprocessed_img\n",
        "\n",
        "# Save images (if 2D, will be saved as gray image)\n",
        "def save_image(file_path, img, orig, percentile=99):\n",
        "    if not orig:\n",
        "      img = np.sum(img, axis=0)\n",
        "      span = abs(np.percentile(img, percentile))\n",
        "      vmin = -span\n",
        "      vmax = span\n",
        "      img = np.clip((img - vmin) / (vmax - vmin), -1, 1)\n",
        "\n",
        "    plt.imsave(file_path, img, cmap='gray')\n",
        "    return img"
      ],
      "outputs": [],
      "metadata": {
        "id": "zXPISKt1Dzj-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ],
      "metadata": {
        "id": "mBIoyZMFrv0t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import csv   \n",
        "\n",
        "# Normalize numpy matrices\n",
        "def normalize(image):\n",
        "  im_min = np.min(image)\n",
        "  im_max = np.max(image)\n",
        "  return (image - im_min) / (im_max - im_min)\n",
        "\n",
        "# Indices of pictures looking far left, right, up, down\n",
        "def get_max_indices():\n",
        "  batch_size = 100\n",
        "  test_indices = []\n",
        "  min_x, max_x, min_y, max_y = float(\"inf\"), float(\"-inf\"), float(\"inf\"), float(\"-inf\")\n",
        "  for k, (row, imFace, imEyeL, imEyeR, faceGrid, gaze) in enumerate(val_loader):\n",
        "    min_x, max_y, min_y, max_y = float(\"inf\"), float(\"-inf\"), float(\"inf\"), float(\"-inf\")\n",
        "    for i in range(batch_size):\n",
        "      if gaze[i][1] < min_x:\n",
        "        min_x = gaze[i][0]\n",
        "        min_x_i = i\n",
        "      if gaze[i][1] > max_x:\n",
        "        max_x = gaze[i][0]\n",
        "        max_x_i = i\n",
        "      if gaze[i][0] < min_y:\n",
        "        min_y = gaze[i][1]\n",
        "        min_y_i = i\n",
        "      if gaze[i][0] > max_y:\n",
        "        max_y = gaze[i][1]\n",
        "        max_y_i = i\n",
        "    test_indices.append([min_y_i, max_y_i, min_x_i, max_x_i])\n",
        "    if k >= 19:\n",
        "      break\n",
        "  test_indices = np.array(test_indices)\n",
        "  return test_indices\n",
        "\n",
        "# Save the SmoothGrad results\n",
        "def save_matrix_sum(file_path, sum_matrix):\n",
        "    header = 'Branch,Batch,Index,Sum'\n",
        "    np.savetxt(file_path, sum_matrix, delimiter=\",\", fmt='%s', header=header)"
      ],
      "outputs": [],
      "metadata": {
        "id": "g2FlYgm_rytU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SmoothGrad Run"
      ],
      "metadata": {
        "id": "Kfm2jNJQr3_1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "target_index = None\n",
        "use_cuda = False\n",
        "results_folder = \"./drive/MyDrive/CSC413Project/results_smoothgrad/\"\n",
        "\n",
        "# Compute smooth gradient\n",
        "smooth_grad = SmoothGrad(\n",
        "    pretrained_model=model,\n",
        "    cuda=use_cuda,\n",
        "    magnitude=True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "pNUWfjh5cKP8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "sum_matrices = []\n",
        "for k, (row, imFace, imEyeL, imEyeR, faceGrid, gaze) in enumerate(train_loader):\n",
        "    # Left, Right, Down, Up\n",
        "    for batch_i, img_i in indices.items():\n",
        "        if k is batch_i:\n",
        "            # Preprocess the images to be passed into SmoothGrad\n",
        "            test_imFace = normalize(imFace[img_i].numpy().copy().transpose(1,2,0))\n",
        "            preprocessed_imFace = preprocess_image(test_imFace, use_cuda)\n",
        "\n",
        "            test_imEyeL = normalize(imEyeL[img_i].numpy().copy().transpose(1,2,0))\n",
        "            preprocessed_imEyeL = preprocess_image(test_imEyeL, use_cuda)\n",
        "\n",
        "            test_imEyeR = normalize(imEyeR[img_i].numpy().copy().transpose(1,2,0))\n",
        "            preprocessed_imEyeR = preprocess_image(test_imEyeR, use_cuda)\n",
        "\n",
        "            test_faceGrid = faceGrid[img_i].unsqueeze(0)\n",
        "\n",
        "            avg_gradients_face, avg_gradients_eyeL, avg_gradients_eyeR = smooth_grad((preprocessed_imFace, preprocessed_imEyeL, preprocessed_imEyeR, test_faceGrid), index=target_index)\n",
        "\n",
        "            # Save images and results depending on the branches and models\n",
        "            if args.model == 'left_eye':\n",
        "                save_image(results_folder+f\"{args.model}_orig_{k},{img_i}.png\", test_imEyeL, True)\n",
        "                save_image(results_folder+f\"{args.model}_smoothgrad_{k},{img_i}.png\", avg_gradients_eyeL, False)\n",
        "                sum_matrix = np.sum(avg_gradients_eyeL)\n",
        "\n",
        "                sum_matrices.append(['Left',k,img_i,sum_matrix])\n",
        "\n",
        "            elif args.model == 'right_eye':\n",
        "                save_image(results_folder+f\"{args.model}_orig_{k},{img_i}.png\", test_imEyeR, True)\n",
        "                save_image(results_folder+f\"{args.model}_smoothgrad_{k},{img_i}.png\", avg_gradients_eyeR, False)\n",
        "                sum_matrix = np.sum(avg_gradients_eyeR)\n",
        "\n",
        "                sum_matrices.append(['Right',k,img_i,sum_matrix])\n",
        "\n",
        "            elif args.model == 'face':\n",
        "                save_image(results_folder+f\"{args.model}_orig_{k},{img_i}.png\", test_imFace, True)\n",
        "                save_image(results_folder+f\"{args.model}_smoothgrad_{k},{img_i}.png\", avg_gradients_face, False)\n",
        "                sum_matrix = np.sum(avg_gradients_face)\n",
        "\n",
        "                sum_matrices.append(['Face',k,img_i,sum_matrix])\n",
        "\n",
        "            elif args.model == 'full':\n",
        "                save_image(results_folder+f\"{args.model}_left_eye_orig_{k},{img_i}.png\", test_imEyeL, True)\n",
        "                save_image(results_folder+f\"{args.model}_right_eye_orig_{k},{img_i}.png\", test_imEyeR, True)\n",
        "                save_image(results_folder+f\"{args.model}_face_orig_{k},{img_i}.png\", test_imFace, True)\n",
        "                save_image(results_folder+f\"{args.model}_left_eye_smoothgrad_{k},{img_i}.png\", avg_gradients_eyeL, False)\n",
        "                save_image(results_folder+f\"{args.model}_right_eye_smoothgrad_{k},{img_i}.png\", avg_gradients_eyeR, False)\n",
        "                save_image(results_folder+f\"{args.model}_face_smoothgrad_{k},{img_i}.png\", avg_gradients_face, False)\n",
        "                \n",
        "                sum_matrix = np.sum(avg_gradients_eyeL)\n",
        "                sum_matrices.append(['Full Left',k,img_i,sum_matrix])\n",
        "                sum_matrix = np.sum(avg_gradients_eyeR)\n",
        "                sum_matrices.append(['Full Right',k,img_i,sum_matrix])\n",
        "                sum_matrix = np.sum(avg_gradients_face)\n",
        "                sum_matrices.append(['Full Face',k,img_i,sum_matrix])\n",
        "\n",
        "    save_matrix_sum(results_folder+f\"{args.model}_sum_matrix.csv\", np.array(sum_matrices))"
      ],
      "outputs": [],
      "metadata": {
        "id": "K9QTP6s97wMC"
      }
    }
  ]
}